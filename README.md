# Data Inference and Applied Machine Learning

##  Project Overview
This repository explores the key concepts, algorithms, and methodologies in **data inference** and **applied machine learning**.  
It is structured around a progressive learning schedule, beginning with statistical learning fundamentals and advancing toward deep learning and reinforcement learning.  
Each section focuses on understanding both theoretical principles and practical implementations using real-world datasets.


### 1. Statistical Learning
Introduces the foundational concepts of learning from data — including inference, model estimation, and the bias-variance tradeoff.  
Focuses on understanding how models generalize and how to interpret statistical patterns from datasets.

### 2. Linear Regression
Explores regression modeling for predicting continuous outcomes.  
Topics include least squares estimation, model assumptions, and evaluation metrics such as R² and RMSE.

### 3. Linear Classification
Covers binary and multi-class classification using linear models such as logistic regression and perceptron learning.  
Emphasizes decision boundaries, loss functions, and regularization.

### 4. Performance Analysis and Error Estimation
Examines methods for evaluating model performance — including cross-validation, confusion matrices, precision, recall, and F1-score.  
Introduces bias, variance, and the importance of balancing underfitting and overfitting.

### 5. Decision Trees
Implements tree-based models for both classification and regression.  
Covers impurity measures (Gini, entropy), pruning techniques, and interpretability advantages.

### 6. Instance-Based Learning
Focuses on algorithms such as k-Nearest Neighbors (kNN).  
Discusses distance metrics, curse of dimensionality, and tradeoffs between accuracy and computational efficiency.

### 7. Ensemble Methods
Explores boosting, bagging, and random forests.  
Highlights how combining multiple models can improve predictive accuracy and robustness.

### 8. Support Vector Machines (SVMs)
Introduces SVMs for linear and non-linear classification using kernel tricks.  
Covers margin maximization, soft margins, and kernel selection.

### 9. Unsupervised Learning
Studies algorithms that find structure in unlabeled data, such as k-means clustering and hierarchical clustering.  
Focuses on feature similarity, dimensionality reduction, and data visualization.

### 10. Neural Networks
Builds the foundation of artificial neural networks — perceptrons, activation functions, and backpropagation.  
Demonstrates feedforward networks for both regression and classification tasks.

### 11. Deep Learning
Expands into deep architectures such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).  
Covers representation learning, gradient descent optimization, and transfer learning.

### 12. Introduction to Reinforcement Learning
Introduces agent-environment interaction models, rewards, and policy learning.  
Explores the basic concepts of Q-learning and Markov Decision Processes (MDPs).

